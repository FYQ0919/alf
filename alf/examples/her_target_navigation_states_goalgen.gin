include 'her_target_navigation_states.gin'

import alf.algorithms.goal_generator
aux_dim=10
SubgoalPlanningGoalGenerator.observation_spec=%observation_spec
SubgoalPlanningGoalGenerator.action_dim=2
SubgoalPlanningGoalGenerator.aux_dim=%aux_dim
SubgoalPlanningGoalGenerator.action_bounds=[-10, 10]

SubgoalPlanningGoalGenerator.min_goal_cost_to_use_plan=10
SubgoalPlanningGoalGenerator.num_subgoals=1
SubgoalPlanningGoalGenerator.plan_margin=0.2
SubgoalPlanningGoalGenerator.normalize_goals=True
SubgoalPlanningGoalGenerator.use_aux_achieved=True

CEMOptimizer.iterations=20
CEMOptimizer.population_size=1000

#ObservationNormalizer.clipping=6.
#TrainerConfig.data_transformer_ctor=@ObservationNormalizer  # during rollout, aux_desired is missing in normalizer input, but present in replay, throwing error.
# Add a normalizer after replay training?

import alf.algorithms.vae
encoding_dim=10
vae/goal_gen_output_spec.observation_spec=%observation_spec
vae/EncodingNetwork.input_tensor_spec=@vae/goal_gen_output_spec()
vae/EncodingNetwork.fc_layer_params=%hidden_layers
vae/EncodingNetwork.preprocessing_combiner=@NestConcat()
import torch
vae/EncodingNetwork.activation=torch.tanh_

VariationalAutoEncoder.z_dim=%encoding_dim
VariationalAutoEncoder.preprocess_network=@vae/EncodingNetwork()

decoder/EncodingNetwork.input_tensor_spec=@TensorSpec((%encoding_dim,))
decoder/EncodingNetwork.fc_layer_params=%hidden_layers
# should be the rl_algorithm's observation_spec (the one generated by goal_gen)
vae/goal_gen_output_dims.observation_spec=%observation_spec
vae/goal_gen_output_dims.aux_dim=%aux_dim
decoder/EncodingNetwork.last_layer_size=@goal_gen_output_dims(%observation_spec, %aux_dim)
decoder/EncodingNetwork.last_activation=@identity

SubgoalPlanningGoalGenerator.vae=@VariationalAutoEncoder()
SubgoalPlanningGoalGenerator.vae_decoder=@decoder/EncodingNetwork()

goal_gen=@SubgoalPlanningGoalGenerator()
Agent.goal_generator=%goal_gen

critic/CriticNetwork.output_tensor_spec=@SubgoalPlanningGoalGenerator/reward_spec(%goal_gen)
value/ValueNetwork.output_tensor_spec=@SubgoalPlanningGoalGenerator/reward_spec(%goal_gen)
