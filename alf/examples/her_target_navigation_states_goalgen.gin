include 'her_target_navigation_states.gin'

import alf.algorithms.goal_generator
aux_dim=10
SubgoalPlanningGoalGenerator.observation_spec=%observation_spec
SubgoalPlanningGoalGenerator.action_dim=2
SubgoalPlanningGoalGenerator.aux_dim=%aux_dim
SubgoalPlanningGoalGenerator.action_bounds=[-10, 10]

SubgoalPlanningGoalGenerator.min_goal_cost_to_use_plan=10
SubgoalPlanningGoalGenerator.num_subgoals=1
SubgoalPlanningGoalGenerator.plan_margin=0.2
SubgoalPlanningGoalGenerator.normalize_goals=True
SubgoalPlanningGoalGenerator.use_aux_achieved=True

CEMOptimizer.iterations=20
CEMOptimizer.population_size=1000

#ObservationNormalizer.clipping=6.
#TrainerConfig.data_transformer_ctor=@ObservationNormalizer  # during rollout, aux_desired is missing in normalizer input, but present in replay, throwing error.
# Add a normalizer after replay training?

import torch
import alf.algorithms.vae
encoding_dim=10

vae/EncodingNetwork.input_tensor_spec=@vae_output_spec(%observation_spec)
vae/EncodingNetwork.activation=torch.tanh_
vae/EncodingNetwork.last_layer_size=%encoding_dim
vae/EncodingNetwork.last_activation=@identity
VariationalAutoEncoder.z_dim=%encoding_dim
#VariationalAutoEncoder.preprocess_network=@vae/EncodingNetwork()  # Commented out for CVAE
vae/EncodingNetwork.name="vae.encoding_net"

# additional setup for conditional VAE:
vae_output_dims.include_obs_dims=False
vae_output_spec.include_obs_dims=False
pr/EncodingNetwork.input_tensor_spec=@cvae_prior_spec(%observation_spec)
pr/EncodingNetwork.activation=torch.tanh_
pr/EncodingNetwork.last_layer_size=@cvae_output_dims(%encoding_dim)
pr/EncodingNetwork.last_activation=@identity
pr/EncodingNetwork.name="z_prior.encoding_net"
z_net=@pr/EncodingNetwork()
VariationalAutoEncoder.z_prior_network=%z_net

cvae/EncodingNetwork.input_tensor_spec=@cvae_input_spec(%observation_spec, %z_net)
cvae/EncodingNetwork.activation=torch.tanh_
cvae/EncodingNetwork.last_layer_size=%encoding_dim
cvae/EncodingNetwork.last_activation=@identity
cvae/EncodingNetwork.name="c_vae.encoding_net"
VariationalAutoEncoder.preprocess_network=@cvae/EncodingNetwork()


decoder/EncodingNetwork.input_tensor_spec=@TensorSpec((%encoding_dim,))
decoder/EncodingNetwork.activation=torch.tanh_
# should be the rl_algorithm's observation_spec (the one generated by goal_gen)
decoder/EncodingNetwork.last_layer_size=@vae_output_dims(%observation_spec, %aux_dim)
decoder/EncodingNetwork.last_activation=@identity
decoder/EncodingNetwork.name="vae_decoder.encoding_net"

SubgoalPlanningGoalGenerator.vae=@VariationalAutoEncoder()
SubgoalPlanningGoalGenerator.vae_decoder=@decoder/EncodingNetwork()

goal_gen=@SubgoalPlanningGoalGenerator()
Agent.goal_generator=%goal_gen

critic/CriticNetwork.output_tensor_spec=@SubgoalPlanningGoalGenerator/reward_spec(%goal_gen)
value/ValueNetwork.output_tensor_spec=@SubgoalPlanningGoalGenerator/reward_spec(%goal_gen)
