include 'ac_target_navigation_states.gin'
include 'ddpg.gin'

# Goal conditioned task setup
GoalTask.success_with_angle_requirement=False
GazeboAgent.goal_conditioned=True
GoalTask.goal_conditioned=True
GoalTask.distraction_penalty_distance_thresh=0.4
GoalTask.end_episode_after_success=0
GoalTask.end_on_hitting_distraction=0
GoalTask.goal_name="target_ball"
GoalTask.max_steps=50
GoalTask.move_goal_during_episode=0
GoalTask.multi_dim_reward=True
GoalTask.reset_time_limit_on_success=0
GoalTask.use_aux_achieved=True
GoalTask.use_curriculum_training=0
PlayGround.max_steps=50

suite_gym.wrap_env.image_channel_first=False

# Networks
import alf.nest.utils
actor/ActorNetwork.preprocessing_combiner=@NestConcat()
critic/CriticNetwork.observation_preprocessing_combiner=@NestConcat()
critic/CriticNetwork.action_preprocessing_combiner=@NestConcat()
critic/CriticNetwork.output_tensor_spec=@get_reward_spec()

hidden_layers=(256,256,256)

value/ValueNetwork.preprocessing_combiner=@NestConcat()
value/ValueNetwork.output_tensor_spec=@get_reward_spec()
value/ValueNetwork.fc_layer_params=%hidden_layers
DdpgAlgorithm.goal_value_net_ctor=@value/ValueNetwork

actor/ActorNetwork.fc_layer_params=%hidden_layers
critic/CriticNetwork.joint_fc_layer_params=%hidden_layers

Agent.rl_algorithm_cls=@DdpgAlgorithm
TrainerConfig.algorithm_ctor=@Agent
DdpgAlgorithm.actor_network_ctor=@actor/ActorNetwork
DdpgAlgorithm.critic_network_ctor=@critic/CriticNetwork
DdpgAlgorithm.use_parallel_network=False
DdpgAlgorithm.rollout_random_action=0.3
DdpgAlgorithm.target_update_period=8

# GoalGenerator
observation_spec=@get_observation_spec()

import alf.algorithms.goal_generator
SubgoalPlanningGoalGenerator.observation_spec=%observation_spec
SubgoalPlanningGoalGenerator.action_dim=2
SubgoalPlanningGoalGenerator.aux_dim=10
SubgoalPlanningGoalGenerator.action_bounds=[-10, 10]

# TrainerConfig
TrainerConfig.initial_collect_steps=10000
TrainerConfig.mini_batch_length=2
TrainerConfig.mini_batch_size=5000
TrainerConfig.num_updates_per_train_iter=40
TrainerConfig.replay_buffer_length=200000

TrainerConfig.summary_interval=20
TrainerConfig.num_iterations=1500
TrainerConfig.num_checkpoints=10
TrainerConfig.evaluate=True
TrainerConfig.eval_interval=500
TrainerConfig.num_eval_episodes=50
